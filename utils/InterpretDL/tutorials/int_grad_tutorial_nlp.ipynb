{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Bi-LSTM Sentiment Classification Models With Integrated Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads the pretrained Bi-LSTM model given by [PaddlePaddle Models](https://github.com/PaddlePaddle/models/tree/release/1.7) and performs sentiment analysis on reviews data. The full official PaddlePaddle sentiment classification tutorial can be found [here](https://github.com/PaddlePaddle/models/tree/release/1.7/PaddleNLP/sentiment_classification). \n",
    "\n",
    "Interpretations of the predictions are generated and visualized using Integrated Gradients algorithm, specifically the `IntGradNLPInterpreter` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have't done so, please first download the pretrained model by running the following command: \n",
    "```\n",
    "wget https://baidu-nlp.bj.bcebos.com/sentiment_classification-1.0.0.tar.gz\n",
    "tar -zxvf sentiment_classification-1.0.0.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "import paddle\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import io\n",
    "\n",
    "sys.path.append('..')\n",
    "import interpretdl as it\n",
    "from assets.bilstm import bilstm_net_emb\n",
    "from interpretdl.data_processor.visualizer import VisualizationTextRecord, visualize_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the word dict from the pretrained model path. Define the `unk_id` to be the word id for unknown token *\\<unk\\>*. Other possible choices include empty token *\\\"\\\"* and pad token *\\<pad\\>*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(file_path):\n",
    "    \"\"\"\n",
    "    load the given vocabulary\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    with io.open(file_path, 'r', encoding='utf8') as f:\n",
    "        wid = 0\n",
    "        for line in f:\n",
    "            if line.strip() not in vocab:\n",
    "                vocab[line.strip()] = wid\n",
    "                wid += 1\n",
    "    vocab[\"<unk>\"] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "MODEL_PATH = \"../../senta_model/bilstm_model/\"\n",
    "PARAMS_PATH = os.path.join(MODEL_PATH, \"params\")\n",
    "VOCAB_PATH = os.path.join(MODEL_PATH, \"word_dict.txt\")\n",
    "\n",
    "word_dict = load_vocab(VOCAB_PATH)\n",
    "unk_id = word_dict[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the paddle model that takes in *word_ids* and *alpha*, and outputs embeddings and prediction probabilities. \n",
    "\n",
    "**Note**: \n",
    "- Inside the function, *alpha* should be multiplied to embeddings because Integrated Gradients method requires calculating the path integral between the baseline (zeros) and the inputs (embeddings).\n",
    "- Here `bilstm_net_emb` is modified from [bilstm_net](https://github.com/PaddlePaddle/models/blob/release/1.7/PaddleNLP/shared_modules/models/classification/nets.py) provided by PaddlePaddle Models. The embedding layer is moved out of the function and returned so that intermediate embeddings can be extracted and apply gradients on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paddle_model(word_ids, alpha):\n",
    "    dict_dim = 1256606\n",
    "    emb_dim = 128\n",
    "    # embedding layer\n",
    "    emb = fluid.embedding(input=word_ids, size=[dict_dim, emb_dim])\n",
    "    emb *= alpha\n",
    "    probs = bilstm_net_emb(emb, None, None, dict_dim, is_prediction=True)\n",
    "    return emb, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `IntGradNLPInterpreter`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = it.IntGradNLPInterpreter(paddle_model, PARAMS_PATH, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the reviews that we want to analyze. \n",
    "\n",
    "The reviews are selected from the sentiment classification dataset. You can download them by running the following command:\n",
    "```\n",
    "wget https://baidu-nlp.bj.bcebos.com/sentiment_classification-dataset-1.0.0.tar.gz\n",
    "tar -zxvf sentiment_classification-dataset-1.0.0.tar.gz\n",
    "```\n",
    "\n",
    "Since the Bi-LSTM model takes fluid.LoDTensor as inputs, reviews are first converted to word ids and then to LoDTensor. For more information regarding LoDTensor, please refer to [the offical documentation](https://www.paddlepaddle.org.cn/documentation/docs/zh/beginners_guide/basic_concept/lod_tensor.html#cn-user-guide-lod-tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    '交通 方便 ； 环境 很好 ； 服务态度 很好 房间 较小',\n",
    "    '这本书 实在 太烂 了 , 什么 朗读 手册 , 一点 朗读 的 内容 都 没有 . 看 了 几页 就 不 想 看 下去 了 .'\n",
    "]\n",
    "\n",
    "reviews = [r.split() for r in reviews]\n",
    "\n",
    "lod = []\n",
    "for c in reviews:\n",
    "    lod.append([word_dict.get(words, unk_id) for words in c])\n",
    "base_shape = [[len(c) for c in lod]]\n",
    "lod = np.array(sum(lod, []), dtype=np.int64)\n",
    "data = fluid.create_lod_tensor(lod, base_shape, fluid.CPUPlace())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we `interpret` reviews and grab weights for each token.\n",
    "\n",
    "Since the output gradients are not grouped by reviews due to the LoDTensor inputs, we use the LoD information to group them into a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels, pred_probs, avg_gradients = ig.interpret(\n",
    "    data, label=None, steps=50, return_pred=True, visual=True)\n",
    "\n",
    "sum_gradients = np.sum(avg_gradients, axis=1).tolist()\n",
    "\n",
    "lod = data.lod()\n",
    "new_array = []\n",
    "for i in range(len(lod[0]) - 1):\n",
    "    new_array.append(\n",
    "        list(zip(reviews[i], sum_gradients[lod[0][i]:lod[0][i + 1]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualizasion purposes, word weights in each review are normalized to better illustrate differences between weights. Results for each review is stored in a list by making use of the `VisualizationTextRecord`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><tr><th>True Label</th><th>Predicted Label (Prob)</th><th>Target Label</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.94)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 交通                        </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 方便                        </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ；                        </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 环境                        </font></mark><mark style=\"background-color: hsl(120, 75%, 71%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 很好                        </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ；                        </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 服务态度                        </font></mark><mark style=\"background-color: hsl(120, 75%, 69%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 很好                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 房间                        </font></mark><mark style=\"background-color: hsl(0, 75%, 85%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 较小                        </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 这本书                        </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 实在                        </font></mark><mark style=\"background-color: hsl(0, 75%, 68%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 太烂                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 了                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ,                        </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 什么                        </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 朗读                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 手册                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ,                        </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 一点                        </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 朗读                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 的                        </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 内容                        </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 都                        </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 没有                        </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> .                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 看                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 了                        </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 几页                        </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 就                        </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 不                        </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 想                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 看                        </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 下去                        </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 了                        </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> .                        </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = [1, 0]\n",
    "recs = []\n",
    "for i, l in enumerate(new_array):\n",
    "    words = [t[0] for t in l]\n",
    "    word_importances = [t[1] for t in l]\n",
    "    word_importances = np.array(word_importances) / np.linalg.norm(\n",
    "        word_importances)\n",
    "    pred_label = pred_labels[i]\n",
    "    pred_prob = pred_probs[i]\n",
    "    true_label = true_labels[i]\n",
    "    interp_class = pred_label\n",
    "    if interp_class == 0:\n",
    "        word_importances = -word_importances\n",
    "    recs.append(\n",
    "        VisualizationTextRecord(words, word_importances, true_label,\n",
    "                                pred_label, pred_prob, interp_class))\n",
    "\n",
    "visualize_text(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
