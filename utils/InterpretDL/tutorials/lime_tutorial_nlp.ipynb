{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Bi-LSTM Sentiment Classification Models With LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads the pretrained Bi-LSTM model given by [PaddlePaddle Models](https://github.com/PaddlePaddle/models/tree/release/1.7) and performs sentiment analysis on reviews data. The full official PaddlePaddle sentiment classification tutorial can be found [here](https://github.com/PaddlePaddle/models/tree/release/1.7/PaddleNLP/sentiment_classification). \n",
    "\n",
    "Interpretations of the predictions are generated and visualized using LIME algorithm, specifically the `LIMENLPInterpreter` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have't done so, please first download the pretrained model by running the following command: \n",
    "```\n",
    "wget https://baidu-nlp.bj.bcebos.com/sentiment_classification-1.0.0.tar.gz\n",
    "tar -zxvf sentiment_classification-1.0.0.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import paddle.fluid as fluid\n",
    "import io\n",
    "\n",
    "sys.path.append('..')\n",
    "import interpretdl as it\n",
    "from assets.bilstm import bilstm\n",
    "from interpretdl.data_processor.visualizer import VisualizationTextRecord, visualize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the word dict from the pretrained model path. Define the `unk_id` to be the word id for empty token *\\\"\\\"*. Other possible choices include *\\<unk\\>* token and *\\<pad\\>* token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(file_path):\n",
    "    \"\"\"\n",
    "    load the given vocabulary\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    with io.open(file_path, 'r', encoding='utf8') as f:\n",
    "        wid = 0\n",
    "        for line in f:\n",
    "            if line.strip() not in vocab:\n",
    "                vocab[line.strip()] = wid\n",
    "                wid += 1\n",
    "    vocab[\"<unk>\"] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "MODEL_PATH = \"../../senta_model/bilstm_model\"\n",
    "VOCAB_PATH = os.path.join(MODEL_PATH, \"word_dict.txt\")\n",
    "PARAMS_PATH = os.path.join(MODEL_PATH, \"params\")\n",
    "\n",
    "word_dict = load_vocab(VOCAB_PATH)\n",
    "unk_id = word_dict[\"\"]  #word_dict[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the paddle model that takes in arbitray number of inputs, in this case word_ids and seq_lens, and outputs prediction probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_DIM = 1256606\n",
    "MAX_SEQ_LEN = 256\n",
    "def paddle_model(word_ids, seq_len):\n",
    "    probs = bilstm(word_ids, seq_len, None, DICT_DIM, is_prediction=True)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a preprocessing function that takes in **a raw string** and outputs the model inputs that can be fed into paddle_model.\n",
    "\n",
    "In this case, the raw string is first splitted and mapped to word ids, then padded to length of MAX_SEQ_LEN. *word_ids* is a list of lists, where each list contains a sequence of padded word ids. *seq_lens* is a list that contains the sequence length of each unpadded word ids in *word_ids*. \n",
    "\n",
    "Since the input data is a single raw string. Both *word_ids* and *seq_lens* has length 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(data):\n",
    "    word_ids = []\n",
    "    sub_word_ids = [word_dict.get(d, unk_id) for d in data.split()]\n",
    "    seq_lens = [len(sub_word_ids)]\n",
    "    if len(sub_word_ids) < MAX_SEQ_LEN:\n",
    "        sub_word_ids += [0] * (MAX_SEQ_LEN - len(sub_word_ids))\n",
    "    word_ids.append(sub_word_ids[:MAX_SEQ_LEN])\n",
    "    return word_ids, seq_lens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `LIMENLPInterpreter`. Define the reviews that we want to analyze. \n",
    "\n",
    "The reviews are selected from the sentiment classification dataset. You can download them by running the following command:\n",
    "```\n",
    "wget https://baidu-nlp.bj.bcebos.com/sentiment_classification-dataset-1.0.0.tar.gz\n",
    "tar -zxvf sentiment_classification-dataset-1.0.0.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime = it.LIMENLPInterpreter(paddle_model, PARAMS_PATH)\n",
    "\n",
    "reviews = [\n",
    "    '交通 方便 ；环境 很好 ；服务态度 很好 房间 较小',\n",
    "    '这本书 实在 太烂 了 , 什么 朗读 手册 , 一点 朗读 的 内容 都 没有 . 看 了 几页 就 不 想 看 下去 了 .'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we iteratively `interpret` each review and grab weights for each token. For visualizasion purposes, word weights in each review are normalized to better illustrate differences between weights. Results for each review is stored in a list by making use of the `VisualizationTextRecord`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-09 14:12:12,990-WARNING: ../../senta_model/bilstm_model/params/checkpoint.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\n",
      "2020-09-09 14:12:13,829-WARNING: ../../senta_model/bilstm_model/params.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\n",
      "2020-09-09 14:12:13,831-WARNING: variable file [ ../../senta_model/bilstm_model/params/fc_3.w_0_moment_0 ../../senta_model/bilstm_model/params/fc_3.b_0_moment_0 ../../senta_model/bilstm_model/params/lstm_1.w_0_moment_0 ../../senta_model/bilstm_model/params/fc_1.w_0_moment_0 ../../senta_model/bilstm_model/params/learning_rate_0 ../../senta_model/bilstm_model/params/fc_0.b_0_moment_0 ../../senta_model/bilstm_model/params/lstm_0.b_0_moment_0 ../../senta_model/bilstm_model/params/embedding_0.w_0_moment_0 ../../senta_model/bilstm_model/params/fc_2.b_0_moment_0 ../../senta_model/bilstm_model/params/lstm_1.b_0_moment_0 ../../senta_model/bilstm_model/params/fc_2.w_0_moment_0 ../../senta_model/bilstm_model/params/fc_0.w_0_moment_0 ../../senta_model/bilstm_model/params/fc_1.b_0_moment_0 ../../senta_model/bilstm_model/params/lstm_0.w_0_moment_0 ] not used\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model from ../../senta_model/bilstm_model/params\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><tr><th>True Label</th><th>Predicted Label (Prob)</th><th>Target Label</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.96)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 交通                        </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 方便                        </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ；环境                        </font></mark><mark style=\"background-color: hsl(120, 75%, 69%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 很好                        </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ；服务态度                        </font></mark><mark style=\"background-color: hsl(120, 75%, 69%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 很好                        </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 房间                        </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 较小                        </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 这本书                        </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 实在                        </font></mark><mark style=\"background-color: hsl(0, 75%, 69%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 太烂                        </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 了                        </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ,                        </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 什么                        </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 朗读                        </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 手册                        </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> ,                        </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 一点                        </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 朗读                        </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 的                        </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 内容                        </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 都                        </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 没有                        </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> .                        </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 看                        </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 了                        </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 几页                        </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 就                        </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 不                        </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 想                        </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 看                        </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 下去                        </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> 了                        </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                         line-height:1.75\"><font color=\"black\"> .                        </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = [1, 0]\n",
    "recs = []\n",
    "\n",
    "for i, review in enumerate(reviews):\n",
    "    pred_class, pred_prob, lime_weights = lime.interpret(\n",
    "        review,\n",
    "        preprocess_fn,\n",
    "        num_samples=200,\n",
    "        batch_size=10,\n",
    "        unk_id=unk_id,\n",
    "        pad_id=0,\n",
    "        return_pred=True)\n",
    "\n",
    "    words = review.split()\n",
    "    interp_class = list(lime_weights.keys())[0]\n",
    "    word_importances = [t[1] for t in lime_weights[interp_class]]\n",
    "    word_importances = np.array(word_importances) / np.linalg.norm(\n",
    "        word_importances)\n",
    "    true_label = true_labels[i]\n",
    "    if interp_class == 0:\n",
    "        word_importances = -word_importances\n",
    "    rec = VisualizationTextRecord(words, word_importances, true_label,\n",
    "                                  pred_class[0], pred_prob[0],\n",
    "                                  interp_class)\n",
    "    recs.append(rec)\n",
    "\n",
    "visualize_text(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
