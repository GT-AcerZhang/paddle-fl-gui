{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering Important Words for Sentiments With NormLIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads the pretrained Bi-LSTM model given by [PaddlePaddle Models](https://github.com/PaddlePaddle/models/tree/release/1.7) and performs sentiment analysis on reviews data. The full official PaddlePaddle sentiment classification tutorial can be found [here](https://github.com/PaddlePaddle/models/tree/release/1.7/PaddleNLP/sentiment_classification). \n",
    "\n",
    "NormLIME method aggregates local models into global and class-specific interpretations. It is effective at recognizing important features. In this notebook, we use NormLIME method, specifically `NormLIMENLPInterpreter`, to discover the words that contribute the most to positive and negative sentiment predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have't done so, please first download the pretrained model and sentiment datasets by running the following command: \n",
    "```\n",
    "wget https://baidu-nlp.bj.bcebos.com/sentiment_classification-1.0.0.tar.gz\n",
    "tar -zxvf sentiment_classification-1.0.0.tar.gz\n",
    "\n",
    "wget https://baidu-nlp.bj.bcebos.com/sentiment_classification-dataset-1.0.0.tar.gz\n",
    "tar -zxvf sentiment_classification-dataset-1.0.0.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import paddle.fluid as fluid\n",
    "import io\n",
    "\n",
    "sys.path.append('..')\n",
    "import interpretdl as it\n",
    "from assets.bilstm import bilstm\n",
    "from interpretdl.data_processor.visualizer import VisualizationTextRecord, visualize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the word dict from the pretrained model path. Define the `unk_id` to be the word id for empty token *\\\"\\\"*. Other possible choices include *\\<unk\\>* token and *\\<pad\\>* token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(file_path):\n",
    "    \"\"\"\n",
    "    load the given vocabulary\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    with io.open(file_path, 'r', encoding='utf8') as f:\n",
    "        wid = 0\n",
    "        for line in f:\n",
    "            if line.strip() not in vocab:\n",
    "                vocab[line.strip()] = wid\n",
    "                wid += 1\n",
    "    vocab[\"<unk>\"] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "MODEL_PATH = \"../../senta_model/bilstm_model\"\n",
    "VOCAB_PATH = os.path.join(MODEL_PATH, \"word_dict.txt\")\n",
    "PARAMS_PATH = os.path.join(MODEL_PATH, \"params\")\n",
    "\n",
    "word_dict = load_vocab(VOCAB_PATH)\n",
    "unk_id = word_dict[\"\"]  #word_dict[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the paddle model that takes in arbitray number of inputs, in this case word_ids and seq_lens, and outputs prediction probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_DIM = 1256606\n",
    "MAX_SEQ_LEN = 256\n",
    "def paddle_model(word_ids, seq_len):\n",
    "    probs = bilstm(word_ids, seq_len, None, DICT_DIM, is_prediction=True)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a preprocessing function that takes in **a raw string** and outputs the model inputs that can be fed into paddle_model.\n",
    "\n",
    "In this case, the raw string is first splitted and mapped to word ids, then padded to length of MAX_SEQ_LEN. *word_ids* is a list of lists, where each list contains a sequence of padded word ids. *seq_lens* is a list that contains the sequence length of each unpadded word ids in *word_ids*. \n",
    "\n",
    "Since the input data is a single raw string. Both *word_ids* and *seq_lens* has length 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(data):\n",
    "    word_ids = []\n",
    "    sub_word_ids = [word_dict.get(d, unk_id) for d in data.split()]\n",
    "    seq_lens = [len(sub_word_ids)]\n",
    "    if len(sub_word_ids) < MAX_SEQ_LEN:\n",
    "        sub_word_ids += [0] * (MAX_SEQ_LEN - len(sub_word_ids))\n",
    "    word_ids.append(sub_word_ids[:MAX_SEQ_LEN])\n",
    "    return word_ids, seq_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the sentiment test dataset into a list. There are 1200 sentences in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total of 1200 sentences\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../senta_data/test.tsv\"\n",
    "\n",
    "data = []\n",
    "with io.open(DATA_PATH, \"r\", encoding='utf8') as fin:\n",
    "    for line in fin:\n",
    "        if line.startswith('text_a'):\n",
    "            continue\n",
    "        cols = line.strip().split(\"\\t\")\n",
    "        if len(cols) != 2:\n",
    "            sys.stderr.write(\"[NOTICE] Error Format Line!\")\n",
    "            continue\n",
    "        data.append(cols[0])\n",
    "print('total of %d sentences' % len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `NormLIMENLPInterpreter`. We save the temporary results into a *.npz* file so that we don't have to run the whole process again if we want to rerun the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normlime = it.NormLIMENLPInterpreter(\n",
    "    paddle_model, PARAMS_PATH, temp_data_file='assets/all_lime_weights_nlp.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin `interpret`ing the whole dataset. This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1200 [00:00<?, ?it/s]2020-09-09 11:01:31,197-WARNING: ../../senta_model/bilstm_model/params/checkpoint.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\n",
      "2020-09-09 11:01:31,954-WARNING: ../../senta_model/bilstm_model/params.pdparams not found, try to load model file saved with [ save_params, save_persistables, save_vars ]\n",
      "2020-09-09 11:01:31,956-WARNING: variable file [ ../../senta_model/bilstm_model/params/embedding_0.w_0_moment_0 ../../senta_model/bilstm_model/params/fc_0.b_0_moment_0 ../../senta_model/bilstm_model/params/lstm_0.b_0_moment_0 ../../senta_model/bilstm_model/params/fc_0.w_0_moment_0 ../../senta_model/bilstm_model/params/lstm_1.b_0_moment_0 ../../senta_model/bilstm_model/params/fc_1.w_0_moment_0 ../../senta_model/bilstm_model/params/fc_1.b_0_moment_0 ../../senta_model/bilstm_model/params/fc_3.b_0_moment_0 ../../senta_model/bilstm_model/params/fc_3.w_0_moment_0 ../../senta_model/bilstm_model/params/fc_2.w_0_moment_0 ../../senta_model/bilstm_model/params/lstm_0.w_0_moment_0 ../../senta_model/bilstm_model/params/fc_2.b_0_moment_0 ../../senta_model/bilstm_model/params/learning_rate_0 ../../senta_model/bilstm_model/params/lstm_1.w_0_moment_0 ] not used\n",
      "  0%|          | 1/1200 [00:03<1:02:21,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model from ../../senta_model/bilstm_model/params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [04:03<00:00,  4.93it/s]\n"
     ]
    }
   ],
   "source": [
    "normlime_weights = normlime.interpret(\n",
    "    data,\n",
    "    preprocess_fn,\n",
    "    unk_id=unk_id,\n",
    "    pad_id=0,\n",
    "    num_samples=500,\n",
    "    batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below, we print the words with top 20 largest weights for positive and negative sentiments. Only words that appear at least 5 times are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>爽</td>\n",
       "      <td>0.037562</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>挺好</td>\n",
       "      <td>0.031876</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>支持</td>\n",
       "      <td>0.026343</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>感动</td>\n",
       "      <td>0.023615</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>很漂亮</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>优点</td>\n",
       "      <td>0.020294</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>满意</td>\n",
       "      <td>0.017170</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>超值</td>\n",
       "      <td>0.016647</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>很满意</td>\n",
       "      <td>0.016316</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>很方便</td>\n",
       "      <td>0.016003</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>所值</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>还不错</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>很好</td>\n",
       "      <td>0.015208</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>周到</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>很好看</td>\n",
       "      <td>0.014550</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>很不错</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>足够</td>\n",
       "      <td>0.013505</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>嘿嘿</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>流畅</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>很舒服</td>\n",
       "      <td>0.012180</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word    weight  frequency\n",
       "0     爽  0.037562          7\n",
       "1    挺好  0.031876          8\n",
       "2    支持  0.026343         16\n",
       "3    感动  0.023615         15\n",
       "4   很漂亮  0.022065         14\n",
       "5    优点  0.020294          9\n",
       "6    满意  0.017170         26\n",
       "7    超值  0.016647         11\n",
       "8   很满意  0.016316         14\n",
       "9   很方便  0.016003         22\n",
       "10   所值  0.015656          5\n",
       "11  还不错  0.015232         24\n",
       "12   很好  0.015208        115\n",
       "13   周到  0.014993          9\n",
       "14  很好看  0.014550          6\n",
       "15  很不错  0.013657         43\n",
       "16   足够  0.013505          9\n",
       "17   嘿嘿  0.012983          6\n",
       "18   流畅  0.012463         11\n",
       "19  很舒服  0.012180         10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = dict(zip(word_dict.values(), word_dict.keys()))\n",
    "# Positive \n",
    "temp = {\n",
    "    id2word[wid]: normlime_weights[1][wid]\n",
    "    for wid in normlime_weights[1]\n",
    "}\n",
    "W = [(word, weight[0], weight[1]) for word, weight in temp.items() if  weight[1] >= 5]\n",
    "pd.DataFrame(data = sorted(W, key=lambda x: -x[1])[:20], columns = ['word', 'weight', 'frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>失望</td>\n",
       "      <td>0.057111</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>很一般</td>\n",
       "      <td>0.048728</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>上当</td>\n",
       "      <td>0.041603</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>粗糙</td>\n",
       "      <td>0.038233</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>恶心</td>\n",
       "      <td>0.036756</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>垃圾</td>\n",
       "      <td>0.033430</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>最差</td>\n",
       "      <td>0.033248</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>较差</td>\n",
       "      <td>0.031293</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>不值</td>\n",
       "      <td>0.025248</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>极差</td>\n",
       "      <td>0.024180</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>不如</td>\n",
       "      <td>0.023782</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>有待</td>\n",
       "      <td>0.020530</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>差</td>\n",
       "      <td>0.020276</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>不是</td>\n",
       "      <td>0.019730</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>不好</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>陈旧</td>\n",
       "      <td>0.017196</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>不爽</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>盗版</td>\n",
       "      <td>0.015661</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>一般</td>\n",
       "      <td>0.014904</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>不对</td>\n",
       "      <td>0.014835</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word    weight  frequency\n",
       "0    失望  0.057111         17\n",
       "1   很一般  0.048728         19\n",
       "2    上当  0.041603          9\n",
       "3    粗糙  0.038233          6\n",
       "4    恶心  0.036756          7\n",
       "5    垃圾  0.033430          7\n",
       "6    最差  0.033248          8\n",
       "7    较差  0.031293          6\n",
       "8    不值  0.025248          8\n",
       "9    极差  0.024180          6\n",
       "10   不如  0.023782         25\n",
       "11   有待  0.020530          6\n",
       "12    差  0.020276        109\n",
       "13   不是  0.019730         81\n",
       "14   不好  0.018558         56\n",
       "15   陈旧  0.017196         13\n",
       "16   不爽  0.015774         12\n",
       "17   盗版  0.015661          5\n",
       "18   一般  0.014904         62\n",
       "19   不对  0.014835          5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative\n",
    "temp = {\n",
    "    id2word[wid]: normlime_weights[0][wid]\n",
    "    for wid in normlime_weights[0]\n",
    "}\n",
    "W = [(word, weight[0], weight[1]) for word, weight in temp.items() if  weight[1] >= 5]\n",
    "pd.DataFrame(data = sorted(W, key=lambda x: -x[1])[:20], columns = ['word', 'weight', 'frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
